{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¡Bienvenidos a la tercera sesión del Mastery Data Science!\n",
    "\n",
    "Ya aprendimos lo necesario y es hora de practicar lo aprendido. \n",
    "\n",
    "## Estructura del día \n",
    "\n",
    "### Primera sesión: 10:00 - 12:00\n",
    "\n",
    "Trabajemos en la sección de ejercicios. No tienen que hacer todos en este tiempo, pero les servirá para resolver dudas que posiblemente les ayuden en la siguiente sección. El documento a trabajar esta en la otra carpeta.\n",
    "\n",
    "### Segunda parte: 12:00 - 15:40 (incluyendo la hora de la comida) \n",
    "\n",
    "Se les presenta un ejercicio de aplicación donde sólo apliquen los comandos básico de Python.\n",
    "\n",
    "### Cierre\n",
    "\n",
    "- Contesta la encuesta en la siguiente liga, nos ayudará a mejorar mucho como el curso y como equipo: http://bit.ly/0919datascience\n",
    "\n",
    "- ¿Comentarios sobre la primer semana?\n",
    "\n",
    "**Nota:** ¡recuerden cargar su ambiente!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto - La Divina comedia\n",
    "## 1. Antes de empezar\n",
    "- Planea tu código: Antes de escribir código debemos sentarnos, pensar que hacer, hacer un plan (se le llama pseudocódigo) y luego ya tienes permiso de escribir código. \n",
    "- ¿No se que hacer? Google it! Seguramente en internet tiene seguramente las respuesta\n",
    "- Divide y conquistaras: trabaja segmentando el código en celdas y revisa que cada acción importante se realice la manera correcta\n",
    "- Si crees que usaras recurrentemente la sección de código que hace algo, sería conveniente hacer una función ¿no? \n",
    "\n",
    "\n",
    "## 2. Descripción \n",
    "\n",
    "Para este ejemplo usaremos del texto en ingles de *La Divina Comedia* escrita por Dante Alighieri y fue descargado desde *Project Gutenberg* con nombre **8800.txt**. Existen muchas maneras de realizar este ejercicio, no te preocupes por lo que hacen los demas. Realiza mediante comandos, no uses funciones hasta que se te pida. \n",
    "\n",
    "\n",
    "**Preguntas**\n",
    "\n",
    "\n",
    "- ¿Cuántas palabras existen en los primeros 5,000 caracteres? \n",
    "- ¿Cuántas palabras únicas existen en el mismo rango? \n",
    "- ¿Importan las mayúsculas y minúsculas? \n",
    "- ¿Cuántas veces aparece la palabra **the** en ese rango? \n",
    "- ¿Puedo saber cuantas veces existe una palabra en el texto cargado? \n",
    "- Crea un diccionario donde asignes el número de apariciones a la palabra existente\n",
    "- ¿Qué pasa con los signos de puntuación, es decir, 'me', 'me;', 'me.', 'me?' y 'me,' son iguales? \n",
    "    - ¿Cuáles existen? ¿Estan todos en la misma posición? \n",
    "- Elimina los signos de puntuación y realiza el mismo ejercicio \n",
    "\n",
    "\n",
    "Ahora crea funciones para realizar las mismas preguntas y usalas para analizar el texto completo (todo un reto). \n",
    "\n",
    "## 3. Comparación de resultados y métodos\n",
    "\n",
    "¡Comparemos la lógica de sus códigos! Nadie piensa igual y la diversidad nos permite encontrar mejores soluciones mediante el diálogo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ¿Quieren más? - Recursos de apoyo \n",
    "\n",
    "- Platarformas: EDX, Coursera, Udemy, DataCamp\n",
    "- Empresas: IBM, Microsoft\n",
    "- Millones de páginas web \n",
    "- Cientos de libros (como los que ya les pasamos) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words:959\n",
      "number of unique words:465\n",
      "number of \"the\" words is 44\n",
      "print order list by number of words\n",
      "('glaucus', 1)\n",
      "('allowed', 1)\n",
      "('memory', 1)\n",
      "('false', 1)\n",
      "('boiling', 1)\n",
      "('en', 1)\n",
      "('mortals', 1)\n",
      "('ran', 1)\n",
      "('sea', 1)\n",
      "('source', 1)\n",
      "('lighter', 1)\n",
      "('being', 1)\n",
      "('bosom', 1)\n",
      "('before', 1)\n",
      "('fast', 1)\n",
      "('bick', 1)\n",
      "('frenzied', 1)\n",
      "('sacred', 1)\n",
      "('enterprise', 1)\n",
      "('calm', 1)\n",
      "('pierian', 1)\n",
      "('sheds', 1)\n",
      "('marsyas', 1)\n",
      "('appear', 1)\n",
      "('higher', 1)\n",
      "('gods', 1)\n",
      "('accompanied', 1)\n",
      "('said', 1)\n",
      "('knits', 1)\n",
      "('stood', 1)\n",
      "('guide', 1)\n",
      "('suffic', 1)\n",
      "('up', 1)\n",
      "('child', 1)\n",
      "('behold', 1)\n",
      "('diver', 1)\n",
      "('steep', 1)\n",
      "('apollo', 1)\n",
      "('tree', 1)\n",
      "('voice', 1)\n",
      "('though', 1)\n",
      "('passage', 1)\n",
      "('line', 1)\n",
      "('bear', 1)\n",
      "('absorb', 1)\n",
      "('bard', 1)\n",
      "('dwelling', 1)\n",
      "('newly', 1)\n",
      "('dost', 1)\n",
      "('threefold', 1)\n",
      "('sky', 1)\n",
      "('vessel', 1)\n",
      "('resemble', 1)\n",
      "('transhuman', 1)\n",
      "('iron', 1)\n",
      "('herb', 1)\n",
      "('than', 1)\n",
      "('divine', 1)\n",
      "('piteous', 1)\n",
      "('ris', 1)\n",
      "('others', 1)\n",
      "('entangled', 1)\n",
      "('second', 1)\n",
      "('joy', 1)\n",
      "('morning', 1)\n",
      "('never', 1)\n",
      "('crown', 1)\n",
      "('lake', 1)\n",
      "('wheel', 1)\n",
      "('mighty', 1)\n",
      "('brief', 1)\n",
      "('reflected', 1)\n",
      "('do', 1)\n",
      "('four', 1)\n",
      "('delphic', 1)\n",
      "('glory', 1)\n",
      "('bodies', 1)\n",
      "('limbs', 1)\n",
      "('risen', 1)\n",
      "('drawn', 1)\n",
      "('mother', 1)\n",
      "('tasted', 1)\n",
      "('beheld', 1)\n",
      "('seest', 1)\n",
      "('bow', 1)\n",
      "('imagination', 1)\n",
      "('bedeck', 1)\n",
      "('impart', 1)\n",
      "('sparks', 1)\n",
      "('look', 1)\n",
      "('sigh', 1)\n",
      "('world', 1)\n",
      "('spark', 1)\n",
      "('off', 1)\n",
      "('rain', 1)\n",
      "('enter', 1)\n",
      "('shame', 1)\n",
      "('what', 1)\n",
      "('unmov', 1)\n",
      "('aspect', 1)\n",
      "('open', 1)\n",
      "('ever', 1)\n",
      "('inflam', 1)\n",
      "('must', 1)\n",
      "('might', 1)\n",
      "('prompts', 1)\n",
      "('wheels', 1)\n",
      "('partakes', 1)\n",
      "('ning', 1)\n",
      "('havens', 1)\n",
      "('gaze', 1)\n",
      "('rises', 1)\n",
      "('natures', 1)\n",
      "('seldom', 1)\n",
      "('gathers', 1)\n",
      "('straight', 1)\n",
      "('act', 1)\n",
      "('mind', 1)\n",
      "('trac', 1)\n",
      "('beam', 1)\n",
      "('dull', 1)\n",
      "('caesar', 1)\n",
      "('near', 1)\n",
      "('other', 1)\n",
      "('theme', 1)\n",
      "('example', 1)\n",
      "('circles', 1)\n",
      "('pierces', 1)\n",
      "('thyself', 1)\n",
      "('cannot', 1)\n",
      "('leaves', 1)\n",
      "('depth', 1)\n",
      "('benign', 1)\n",
      "('gain', 1)\n",
      "('r', 1)\n",
      "('clearly', 1)\n",
      "('create', 1)\n",
      "('blaze', 1)\n",
      "('constellation', 1)\n",
      "('spirit', 1)\n",
      "('serve', 1)\n",
      "('joins', 1)\n",
      "('beyond', 1)\n",
      "('keener', 1)\n",
      "('pray', 1)\n",
      "('satisfied', 1)\n",
      "('therefore', 1)\n",
      "('admire', 1)\n",
      "('seen', 1)\n",
      "('henceforth', 1)\n",
      "('rest', 1)\n",
      "('elsewhere', 1)\n",
      "('utt', 1)\n",
      "('blackness', 1)\n",
      "('seem', 1)\n",
      "('fit', 1)\n",
      "('claims', 1)\n",
      "('whose', 1)\n",
      "('sphere', 1)\n",
      "('high', 1)\n",
      "('perchance', 1)\n",
      "('foot', 1)\n",
      "('honour', 1)\n",
      "('themselves', 1)\n",
      "('small', 1)\n",
      "('lunar', 1)\n",
      "('shaken', 1)\n",
      "('cause', 1)\n",
      "('mak', 1)\n",
      "('eagle', 1)\n",
      "('whither', 1)\n",
      "('hearts', 1)\n",
      "('erspread', 1)\n",
      "('far', 1)\n",
      "('shall', 1)\n",
      "('parnassus', 1)\n",
      "('lamp', 1)\n",
      "('largeliest', 1)\n",
      "('bright', 1)\n",
      "('happiest', 1)\n",
      "('rds', 1)\n",
      "('resplendence', 1)\n",
      "('together', 1)\n",
      "('primal', 1)\n",
      "('ask', 1)\n",
      "('void', 1)\n",
      "('peer', 1)\n",
      "('song', 1)\n",
      "('thee', 1)\n",
      "('make', 1)\n",
      "('ocean', 1)\n",
      "('need', 1)\n",
      "('favour', 1)\n",
      "('printed', 1)\n",
      "('remov', 1)\n",
      "('lips', 1)\n",
      "('thirst', 1)\n",
      "('instinct', 1)\n",
      "('rais', 1)\n",
      "('thing', 1)\n",
      "('proper', 1)\n",
      "('belov', 1)\n",
      "('worldly', 1)\n",
      "('wreath', 1)\n",
      "('ear', 1)\n",
      "('pow', 1)\n",
      "('been', 1)\n",
      "('smiles', 1)\n",
      "('be', 1)\n",
      "('both', 1)\n",
      "('deprav', 1)\n",
      "('gazing', 1)\n",
      "('harmony', 1)\n",
      "('gives', 1)\n",
      "('suffer', 1)\n",
      "('hast', 1)\n",
      "('became', 1)\n",
      "('gracious', 1)\n",
      "('hand', 1)\n",
      "('already', 1)\n",
      "('love', 1)\n",
      "('animals', 1)\n",
      "('hither', 1)\n",
      "('how', 1)\n",
      "('end', 1)\n",
      "('passages', 1)\n",
      "('let', 1)\n",
      "('flood', 1)\n",
      "('relate', 1)\n",
      "('see', 1)\n",
      "('aim', 1)\n",
      "('could', 1)\n",
      "('answer', 1)\n",
      "('sire', 1)\n",
      "('charm', 1)\n",
      "('shine', 1)\n",
      "('admiration', 1)\n",
      "('remaining', 1)\n",
      "('again', 1)\n",
      "('sound', 1)\n",
      "('diversely', 1)\n",
      "('city', 1)\n",
      "('rance', 1)\n",
      "('witness', 1)\n",
      "('come', 1)\n",
      "('happy', 1)\n",
      "('scap', 1)\n",
      "('bears', 1)\n",
      "('deep', 1)\n",
      "('makes', 1)\n",
      "('laurel', 1)\n",
      "('cirrhaean', 1)\n",
      "('eve', 1)\n",
      "('shadow', 1)\n",
      "('newness', 1)\n",
      "('last', 1)\n",
      "('left', 1)\n",
      "('eyesight', 1)\n",
      "('wills', 1)\n",
      "('even', 1)\n",
      "('brows', 1)\n",
      "('pass', 1)\n",
      "('divested', 1)\n",
      "('foliage', 1)\n",
      "('dragg', 1)\n",
      "('lean', 1)\n",
      "('impression', 1)\n",
      "('steps', 1)\n",
      "('brute', 1)\n",
      "('hemisphere', 1)\n",
      "('thanks', 1)\n",
      "('hadst', 1)\n",
      "('cross', 1)\n",
      "('another', 1)\n",
      "('pilgrim', 1)\n",
      "('upwards', 1)\n",
      "('whiteness', 1)\n",
      "('will', 1)\n",
      "('turn', 1)\n",
      "('exceeds', 1)\n",
      "('tell', 1)\n",
      "('casts', 1)\n",
      "('nathless', 1)\n",
      "('surpasseth', 1)\n",
      "('rul', 1)\n",
      "('whenas', 1)\n",
      "('around', 1)\n",
      "('nor', 1)\n",
      "('proof', 1)\n",
      "('felt', 1)\n",
      "('were', 1)\n",
      "('triumph', 1)\n",
      "('follow', 1)\n",
      "('vast', 1)\n",
      "('desired', 1)\n",
      "('weak', 1)\n",
      "('binds', 1)\n",
      "('almost', 1)\n",
      "('above', 1)\n",
      "('spring', 1)\n",
      "('tow', 1)\n",
      "('measur', 1)\n",
      "('us', 1)\n",
      "('art', 1)\n",
      "('believ', 1)\n",
      "('inspir', 1)\n",
      "('unsheath', 1)\n",
      "('matter', 1)\n",
      "('fancy', 1)\n",
      "('change', 1)\n",
      "('hence', 1)\n",
      "('issue', 1)\n",
      "('shalt', 1)\n",
      "('ring', 1)\n",
      "('suddenly', 1)\n",
      "('different', 1)\n",
      "('breast', 1)\n",
      "('view', 1)\n",
      "('upward', 1)\n",
      "('breathe', 1)\n",
      "('each', 1)\n",
      "('directs', 1)\n",
      "('although', 1)\n",
      "('wax', 1)\n",
      "('aid', 1)\n",
      "('inwardly', 1)\n",
      "('giv', 1)\n",
      "('they', 1)\n",
      "('troubled', 1)\n",
      "('labour', 1)\n",
      "('broad', 1)\n",
      "('canto', 1)\n",
      "('o', 2)\n",
      "('at', 2)\n",
      "('words', 2)\n",
      "('him', 2)\n",
      "('eternal', 2)\n",
      "('here', 2)\n",
      "('less', 2)\n",
      "('own', 2)\n",
      "('forth', 2)\n",
      "('ne', 2)\n",
      "('course', 2)\n",
      "('into', 2)\n",
      "('began', 2)\n",
      "('universe', 2)\n",
      "('among', 2)\n",
      "('store', 2)\n",
      "('doubt', 2)\n",
      "('mov', 2)\n",
      "('realm', 2)\n",
      "('didst', 2)\n",
      "('desire', 2)\n",
      "('ken', 2)\n",
      "('better', 2)\n",
      "('only', 2)\n",
      "('whence', 2)\n",
      "('some', 2)\n",
      "('grace', 2)\n",
      "('return', 2)\n",
      "('approaching', 2)\n",
      "('earth', 2)\n",
      "('saw', 2)\n",
      "('day', 2)\n",
      "('flame', 2)\n",
      "('god', 2)\n",
      "('place', 2)\n",
      "('have', 2)\n",
      "('temper', 2)\n",
      "('myself', 2)\n",
      "('first', 2)\n",
      "('worth', 2)\n",
      "('new', 2)\n",
      "('mortal', 2)\n",
      "('intellect', 2)\n",
      "('best', 2)\n",
      "('or', 2)\n",
      "('set', 2)\n",
      "('thoughts', 2)\n",
      "('s', 2)\n",
      "('long', 2)\n",
      "('yet', 2)\n",
      "('part', 2)\n",
      "('beatrice', 2)\n",
      "('bent', 2)\n",
      "('whom', 2)\n",
      "('wont', 2)\n",
      "('e', 2)\n",
      "('order', 2)\n",
      "('creatures', 2)\n",
      "('she', 2)\n",
      "('kind', 2)\n",
      "('know', 2)\n",
      "('human', 2)\n",
      "('after', 2)\n",
      "('rise', 2)\n",
      "('great', 2)\n",
      "('fire', 2)\n",
      "('thence', 2)\n",
      "('much', 3)\n",
      "('upon', 3)\n",
      "('form', 3)\n",
      "('st', 3)\n",
      "('if', 3)\n",
      "('their', 3)\n",
      "('now', 3)\n",
      "('may', 3)\n",
      "('er', 3)\n",
      "('eyes', 3)\n",
      "('heav', 3)\n",
      "('are', 3)\n",
      "('had', 3)\n",
      "('comes', 3)\n",
      "('power', 3)\n",
      "('things', 3)\n",
      "('mine', 3)\n",
      "('then', 3)\n",
      "('he', 3)\n",
      "('it', 3)\n",
      "('our', 3)\n",
      "('hath', 4)\n",
      "('more', 4)\n",
      "('who', 4)\n",
      "('when', 4)\n",
      "('but', 4)\n",
      "('made', 4)\n",
      "('there', 4)\n",
      "('light', 4)\n",
      "('through', 4)\n",
      "('sun', 4)\n",
      "('those', 4)\n",
      "('not', 4)\n",
      "('fix', 4)\n",
      "('thus', 4)\n",
      "('all', 4)\n",
      "('one', 4)\n",
      "('n', 5)\n",
      "('thy', 5)\n",
      "('its', 5)\n",
      "('his', 6)\n",
      "('on', 6)\n",
      "('such', 6)\n",
      "('was', 6)\n",
      "('which', 6)\n",
      "('this', 7)\n",
      "('by', 7)\n",
      "('her', 7)\n",
      "('for', 7)\n",
      "('is', 8)\n",
      "('so', 8)\n",
      "('my', 9)\n",
      "('a', 10)\n",
      "('in', 11)\n",
      "('from', 11)\n",
      "('as', 12)\n",
      "('me', 12)\n",
      "('thou', 13)\n",
      "('with', 13)\n",
      "('i', 14)\n",
      "('to', 20)\n",
      "('that', 23)\n",
      "('and', 24)\n",
      "('of', 25)\n",
      "('d', 36)\n",
      "('the', 44)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def read_file(fileName, num_carac):\n",
    "    my_file = open(fileName, \"r\")\n",
    "    my_result = ''\n",
    "    found = False\n",
    "    for line in my_file:\n",
    "        found = 'CANTO I' in line or found\n",
    "        if (found):\n",
    "            my_result += line\n",
    "    length_text = len(my_result)\n",
    "    num_carac_fix = num_carac\n",
    "    if (num_carac_fix > length_text):\n",
    "        num_carac_fix = length_text\n",
    "    return (my_result[:num_carac_fix])\n",
    "text_file = read_file('8800.txt',5000)\n",
    "\n",
    "#print(text_file)\n",
    "\n",
    "word_list = re.sub(\"[^\\w]\", \" \",  text_file).lower().split()\n",
    "print(f'number of words:{len(word_list)}')\n",
    "set_words = set(word_list)\n",
    "number_unique_word = len(set_words)\n",
    "print(f'number of unique words:{number_unique_word}')\n",
    "\n",
    "def count_words(word,word_list):\n",
    "    result = 0\n",
    "    for aword in word_list:\n",
    "        if aword == word:\n",
    "            result=result+1\n",
    "    return result\n",
    "\n",
    "count_the = count_words('the', word_list)\n",
    "print(f'number of \"the\" words is {count_the}')\n",
    "\n",
    "def build_dictonary(word_list):\n",
    "    set_words = set(word_list)\n",
    "    key_words = list(set_words)\n",
    "    result_dict = {}\n",
    "    for akey_word in key_words:\n",
    "        result_dict[akey_word] = count_words(akey_word,word_list)\n",
    "    return result_dict\n",
    "\n",
    "words_dict = build_dictonary(word_list)\n",
    "#print(words_dict)\n",
    "\n",
    "a_list = [(k, v) for k, v in words_dict.items()]\n",
    "def custom_sort(item):\n",
    "     return item[1]\n",
    "a_list.sort(key=custom_sort)\n",
    "\n",
    "print(f'print order list by number of words')\n",
    "for a_elem in a_list:\n",
    "    print(a_elem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Philip', 'K', 'Electric']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s1 = \"Philip K Dick's Electric Dreams\"\n",
    "s2 = \"Philip K Dicks Electric'd Dream\"\n",
    "re.sub(\"[a-zA-Z]+\\'?s\", \" \", s1).split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
