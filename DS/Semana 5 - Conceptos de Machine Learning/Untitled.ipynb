{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "data.target[[10, 50, 85]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': '/opt/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/breast_cancer.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(data['data'], columns = data['feature_names'])\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)\n",
    "df_features.shape\n",
    "\n",
    "df_features['target'] =  data['target']\n",
    "m_X = df_features[list(df_features.columns)]\n",
    "m_y = data['target']\n",
    "\n",
    "\n",
    "feat_train, feat_test, target_train, target_test = train_test_split(m_X, m_y, test_size=0.30, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 0  Actual: 0.0\n",
      "Predicted: 1  Actual: 0.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 1.0\n",
      "Predicted: 1  Actual: 0.0\n",
      "Predicted: 1  Actual: 0.0\n",
      "Accuracy: 0.9181286549707602\n"
     ]
    }
   ],
   "source": [
    "features = data['feature_names']\n",
    "neighbors = 6\n",
    "classifier = KNeighborsClassifier(neighbors)\n",
    "classifier.fit(feat_train[features], feat_train['target'])\n",
    "predictions = classifier.predict(feat_test[features])\n",
    "# Calculate accuracy\n",
    "numtrain = len(feat_train)\n",
    "numtest = len(feat_test)\n",
    "correct = 0\n",
    "for i in range(numtest):\n",
    "    print ('Predicted:', predictions[i], ' Actual:', feat_test.iloc[i]['target'])\n",
    "    if predictions[i] == feat_test.iloc[i]['target']: correct +=1\n",
    "print ('Accuracy:', float(correct)/float(numtest))\n",
    "\n",
    "#predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted target   0   1\n",
       "Actual target           \n",
       "0                 58   8\n",
       "1                  6  99"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##peroo vamos a ver toda la dataaa\n",
    "pd.crosstab(feat_test['target'], predictions, rownames=['Actual target'], colnames=['Predicted target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict_proba(feat_test[features])[0:len(feat_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "all_accuracies = cross_val_score(estimator=classifier, X=feat_train, y=target_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91358025 0.9375     0.94936709 0.94936709 0.93670886]\n",
      "0.9373046569776526\n"
     ]
    }
   ],
   "source": [
    "print(all_accuracies)\n",
    "print(all_accuracies.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
